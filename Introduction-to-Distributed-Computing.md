An introduction to Distributed Computing will be added to Fall 2018

# What is Distributed Computing?

Distributed computing studies efficient use of physically separate computational systems. 

Simple distributed computing problems might span just a handful machines or even millions of platforms. For example, you might run your interactive 3D simulation on a remote machine, store your world data on another server and wonder if you can improve the latency of your Virtual Space.  Or you might create a highly parallel search algorithm, where each compute node independently models and searches for an how a protein molecule can fold, and wonder how to best use everyone's spare computation and network capacity. Though these are examples of computing span multiple machines, the field of "Distributed Computing" is even more complex and interesting than these "simple" problems.

Distributed Computing is interesting for the very same reasons that make it difficult! So far with system programming we've already introduced three foundational concepts - concurrency, networking and data flow, fault-tolerant computing and communication - that are important in Distributed Computing problems. The _distributed_ part however also means we need to study messaging, coordination and synchronicity (timing) between our systems and how we can best partition the computation and data of a particular kind of computing problem across multiple systems that are physically separated. 

# Example Timing and Coordination and Fault Tolerant Problems

_Todo introduce 3 examples_

# Example data and algorithm problems

_Todo introduce 3 examples_

# Example Exam Review Questions
